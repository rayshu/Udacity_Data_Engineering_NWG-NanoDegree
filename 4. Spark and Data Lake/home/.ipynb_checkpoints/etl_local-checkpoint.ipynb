{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, \\\n",
    "    DoubleType as Dbl, LongType as Long, StringType as Str, IntegerType as Int, TimestampType as timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://549010aadc9a:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4f84633fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "spark=create_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data = 'data/'\n",
    "output_data = 'output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_data = input_data + 'song_data/*/*/*/'\n",
    "\n",
    "song_schema = R([\n",
    "        Fld('artist_id', Str()),\n",
    "        Fld('artist_latitude', Dbl()),\n",
    "        Fld('artist_location', Str()),\n",
    "        Fld('artist_longitude', Dbl()),\n",
    "        Fld('artist_name', Str()),\n",
    "        Fld('duration', Dbl()),\n",
    "        Fld('num_songs', Int()),\n",
    "        Fld('song_id', Str()),\n",
    "        Fld('title', Str()),\n",
    "        Fld('year', Int())\n",
    "    ])\n",
    "\n",
    "song_df = spark.read.json(song_data, schema=song_schema)\n",
    "song_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Songs Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOGOSOV12AF72A285E|   ¿Dónde va Chichi?|ARGUVEV1187B98BA17|1997|313.12934|\n",
      "|SOMZWCG12A8C13C480|    I Didn't Mean To|ARD7TVE1187B99BFB1|   0|218.93179|\n",
      "|SOUPIRU12A6D4FA1E1| Der Kleine Dompfaff|ARJIE2Y1187B994AB7|   0|152.92036|\n",
      "|SOXVLOJ12AB0189215|     Amor De Cabaret|ARKRRTF1187B9984DA|   0|177.47546|\n",
      "|SOWTBJW12AC468AC6E|Broken-Down Merry...|ARQGYP71187FB44566|   0|151.84934|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table = song_df.select([\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\"]).dropDuplicates([\"song_id\"])\n",
    "songs_table.show(5)\n",
    "songs_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table.write.parquet(output_data + 'songs/', mode = \"overwrite\", partitionBy = [\"year\", \"artist_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Artists Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|         artist_id|         artist_name|     artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|AR9AWNF1187B9AB0B4|Kenny G featuring...|Seattle, Washingt...|           null|            null|\n",
      "|AR0IAWL1187B9A96D0|        Danilo Perez|              Panama|         8.4177|       -80.11278|\n",
      "|AR0RCMP1187FB3F427|    Billie Jo Spears|        Beaumont, TX|       30.08615|       -94.10158|\n",
      "|AREDL271187FB40F44|        Soul Mekanik|                    |           null|            null|\n",
      "|ARI3BMM1187FB4255E|        Alice Stuart|          Washington|        38.8991|         -77.029|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_table = song_df.select([\"artist_id\", \"artist_name\", \"artist_location\", \"artist_latitude\", \"artist_longitude\"]).dropDuplicates([\"artist_id\"])\n",
    "artists_table.show(5)\n",
    "artists_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_table.write.parquet(output_data + 'artists/', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_data = input_data + \"log_data/\"\n",
    "\n",
    "log_schema = R([\n",
    "    Fld('artist', Str()),\n",
    "    Fld('auth', Str()),\n",
    "    Fld('firstName', Str()),\n",
    "    Fld('gender', Str()),\n",
    "    Fld('itemInSession', Str()),\n",
    "    Fld('lastName', Str()),\n",
    "    Fld('length', Dbl()),\n",
    "    Fld('level', Str()),\n",
    "    Fld('location', Str()),\n",
    "    Fld('method', Str()),\n",
    "    Fld('page', Str()),\n",
    "    Fld('registration', Dbl()),\n",
    "    Fld('sessionId', Str()),\n",
    "    Fld('song', Str()),\n",
    "    Fld('status', Str()),\n",
    "    Fld('ts', Long()),\n",
    "    Fld('userAgent', Str()),\n",
    "    Fld('userId', Str()),\n",
    "    ])\n",
    "    \n",
    "log_df = spark.read.json(log_data, schema=log_schema)\n",
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[artist: string, auth: string, firstName: string, gender: string, itemInSession: string, lastName: string, length: double, level: string, location: string, method: string, page: string, registration: double, sessionId: string, song: string, status: string, ts: bigint, userAgent: string, userId: string]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df =log_df.where('page=\"NextSong\"')\n",
    "log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Users Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+------+-----+\n",
      "|userId|firstName|lastName|gender|level|\n",
      "+------+---------+--------+------+-----+\n",
      "|    51|     Maia|   Burke|     F| free|\n",
      "|     7|   Adelyn|  Jordan|     F| free|\n",
      "|    15|     Lily|    Koch|     F| paid|\n",
      "|    54|    Kaleb|    Cook|     M| free|\n",
      "|   101|   Jayden|     Fox|     M| free|\n",
      "+------+---------+--------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_table = log_df.select([\"userId\", \"firstName\", \"lastName\", \"gender\", \"level\"]).dropDuplicates([\"userId\"])\n",
    "users_table.show(5)\n",
    "users_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.write.parquet(output_data + 'users/' + 'users.parquet', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Time Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           timestamp|\n",
      "+--------------------+\n",
      "|2018-11-15 00:30:...|\n",
      "|2018-11-15 00:41:...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import TimestampType\n",
    "get_timestamp = udf(lambda x: datetime.fromtimestamp((x / 1000)), TimestampType())\n",
    "log_df = log_df.withColumn(\"timestamp\", get_timestamp(col(\"ts\")))\n",
    "log_df.select('timestamp').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-02 12:30:...|  12|  2|  44|   11|2018|    Fri|\n",
      "|2018-11-03 19:01:...|  19|  3|  44|   11|2018|    Sat|\n",
      "|2018-11-04 06:33:...|   6|  4|  44|   11|2018|    Sun|\n",
      "|2018-11-04 19:19:...|  19|  4|  44|   11|2018|    Sun|\n",
      "|2018-11-05 16:31:...|  16|  5|  45|   11|2018|    Mon|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table = log_df.select(\n",
    "    col('timestamp').alias('start_time'),\n",
    "    hour('timestamp').alias('hour'),\n",
    "    dayofmonth('timestamp').alias('day'),\n",
    "    weekofyear('timestamp').alias('week'),\n",
    "    month('timestamp').alias('month'),\n",
    "    year('timestamp').alias('year'),\n",
    "    date_format(col(\"timestamp\"), \"E\").alias(\"weekday\")\n",
    ").dropDuplicates([\"start_time\"])\n",
    "time_table.show(5)\n",
    "time_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.write.parquet(output_data + 'time/', mode = \"overwrite\", partitionBy = [\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Songplays Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songplay_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>level</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>location</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-21 21:56:47.796</td>\n",
       "      <td>15</td>\n",
       "      <td>paid</td>\n",
       "      <td>SOZCTXZ12AB0182364</td>\n",
       "      <td>AR5KOSW1187FB35FF4</td>\n",
       "      <td>818</td>\n",
       "      <td>Chicago-Naperville-Elgin, IL-IN-WI</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   songplay_id              start_time user_id level             song_id  \\\n",
       "0            0 2018-11-21 21:56:47.796      15  paid  SOZCTXZ12AB0182364   \n",
       "\n",
       "            artist_id session_id                            location  \\\n",
       "0  AR5KOSW1187FB35FF4        818  Chicago-Naperville-Elgin, IL-IN-WI   \n",
       "\n",
       "                                          user_agent  year  month  \n",
       "0  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...  2018     11  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df.createOrReplaceTempView(\"song_data\")\n",
    "log_df.createOrReplaceTempView(\"log_data\")\n",
    "    \n",
    "songplays_table = spark.sql(\"\"\"\n",
    "                            SELECT monotonically_increasing_id() as songplay_id,\n",
    "                                timestamp as start_time,\n",
    "                                userId as user_id,\n",
    "                                level,\n",
    "                                song_id,\n",
    "                                artist_id,\n",
    "                                sessionId as session_id,\n",
    "                                location,\n",
    "                                userAgent as user_agent,\n",
    "                                year(timestamp) as year, \n",
    "                                month(timestamp) as month\n",
    "                            FROM log_data log\n",
    "                            JOIN song_data song\n",
    "                            ON (log.song = song.title\n",
    "                            AND log.length = song.duration\n",
    "                            AND log.artist = song.artist_name)\n",
    "                            \"\"\")\n",
    "songplays_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.write.parquet(output_data + 'songplays/', mode = \"overwrite\", partitionBy = ['year','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
