{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Gathering Data\n",
    "\n",
    "In this step, data needs to be gathered from 3 different sources and are to be stored into dataframes:\n",
    "  - `twitter_archive_df`: Directly reading the twitter-archive-enhanced.csv from local using pandas read_csv method\n",
    "  - `predictions_df`: Downloading the data from the given URL using requests library\n",
    "  - `count_df`: Gathering data from twitter API using the tweepy library and store the result into twitter-json.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Assessing Data\n",
    "\n",
    "In this step, both visual and programmatic assessment must be used to find out atleast 8 Qality issues and atleast 2 Tidiness issues.\n",
    "Upon assessment I found out following issues.\n",
    "\n",
    "### Quality \n",
    "| SNo. | Issue | Table|\n",
    "| :--- | :-- | :--- |\n",
    "| 1. |  `twitter_archive_df`|  incorrect datatype(tweet_id, in_reply_to_status_id, in_reply_to_user_id, timestamp, source,retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp) | \n",
    "| 2. | `twitter_archive_df` |  Delete the Retweets so that we only have the original tweets | \n",
    "| 3. | `twitter_archive_df` |  name, doggo, fluffer, pupper, puppo has None for NaN | \n",
    "| 4. | `twitter_archive_df` |  source contain html quotes | \n",
    "| 5. | `twitter_archive_df` | Delete invalid dog names |\n",
    "| 6. | `twitter_archive_df` | Incorrect numerator values |\n",
    "| 7. | `predictions_df` | incorrect datatype(tweet_id, p1, p2, p3) | \n",
    "| 8. | `predictions_df` | remove p1_dog, p2_dog, p3_dog set as False as these are not dog types | \n",
    "| 9. | `count_df` | incorrect datatype(tweet_id) | \n",
    "\n",
    "### Tidiness\n",
    "| SNo. | Issue | \n",
    "| :--- | :--- | \n",
    "| 1. | doggo, floofer, pupper, puppo should be in one column | \n",
    "| 2. | Combine P1, P2, and P3 into prediction_type, and cofindence level columns | \n",
    "| 3. | join all three tables |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cleaning the Data\n",
    "\n",
    "Once all the issues were documented, I followed the Define, Code, and Test to Clean the data using the knowledge I gained from the precious lessons.\n",
    "\n",
    "### Quality Issues:\n",
    "1. Incorrect datatypes in twitter_archive_df (tweet_id, in_reply_to_status_id, in_reply_to_user_id, timestamp, source, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp): IDs (like tweet_id, in_reply_to_status_id etc.) should be treated as string type, and timestamp fields should be of datetime type\n",
    "2. Deleted the Retweets so that we only have the original tweets\n",
    "3. 5 columns(name, doggo, fluffer, pupper, puppo) in twitter_archive_df had None for NaN: None will be treated as a valid non null value in calculations, hence I changed all the None to NaN\n",
    "4. source field in twitter_archive_df had html codes which won't be of any use during analysis and visualization\n",
    "5. There were many tweets having No dog names or dog names which were not valid like a, an, the etc., so I removed all null/None as dog names and any name starting with a lowercase\n",
    "6. There were incorrect numerators captured for tweets with decimal point ratings\n",
    "7. Incorrect datatypes in predictions_df(tweet_id, p1, p2, p3)\n",
    "8. Removed p1_dog, p2_dog, p3_dog set as False as these are not dog types\n",
    "9. Incorrect DataType for tweet_id in count_df\n",
    "\n",
    "\n",
    "### Tidiness Issues:\n",
    "1. Merged doggo, floofer, pupper, puppo in one column called dog_stage\n",
    "2. Combined p1, p1_conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog into prediction_type, and cofindence_level columns as all these columns convey this information only\n",
    "3. Joined all three dataframes into 1 dataframe called twitter_archive_master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Storing Data\n",
    "Once all the above steps are done, I stored the final wrangles data into twitter-archive-master.csv for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
